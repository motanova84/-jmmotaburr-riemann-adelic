name: 🧮 Comprehensive Riemann-Adelic CI/CD

on:
  push:
    branches: [main, develop]
    paths:
      - '**/*.py'
      - 'notebooks/**/*.ipynb'
      - 'requirements.txt'
      - '.github/workflows/**'
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      run_full_validation:
        description: 'Run full validation with high precision'
        required: false
        default: 'false'
        type: boolean
      precision_level:
        description: 'Precision level (t1e8, t1e10, t1e12)'
        required: false
        default: 't1e8'
        type: choice
        options:
          - t1e8
          - t1e10
          - t1e12

env:
  # Optimized parameters for CI performance
  PRIME_COUNT: ${{ github.event.inputs.run_full_validation == 'true' && '1000' || '100' }}
  PRIME_POWERS: 5
  ZERO_COUNT: ${{ github.event.inputs.run_full_validation == 'true' && '1000' || '100' }}
  INTEGRATION_T: ${{ github.event.inputs.run_full_validation == 'true' && '50' || '10' }}
  PRECISION_DPS: ${{ github.event.inputs.run_full_validation == 'true' && '50' || '25' }}
  PRECISION_LEVEL: ${{ github.event.inputs.precision_level || 't1e8' }}

jobs:
  setup-and-validate:
    name: 🔧 Setup & Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    outputs:
      python-version: ${{ steps.setup-python.outputs.python-version }}
      cache-key: ${{ steps.cache-deps.outputs.cache-hit }}
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        
      - name: 🐍 Setup Python
        id: setup-python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          
      - name: 💾 Cache dependencies
        id: cache-deps
        uses: actions/cache@v4
        with:
          path: ~/.local
          key: ${{ runner.os }}-python-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/requirements.txt') }}
          
      - name: 📦 Install dependencies
        if: steps.cache-deps.outputs.cache-hit != 'true'
        run: |
          python -m pip install --upgrade pip
          pip install --user -r requirements.txt
          pip install --user flake8 black isort pytest-cov
          
      - name: 🔍 Code quality checks
        run: |
          # Check Python syntax
          python -m py_compile validate_explicit_formula.py utils/*.py tests/*.py
          
          # Optional linting (don't fail on style issues)
          echo "🎨 Running code quality checks..."
          flake8 --max-line-length=120 --ignore=E203,W503,E501 *.py utils/ tests/ || echo "⚠️ Style issues found (non-blocking)"
          
      - name: 📋 Validate project structure
        run: |
          echo "🔍 Validating project structure..."
          required_files=("requirements.txt" "validate_explicit_formula.py" "utils/mellin.py" "tests/test_validation.py")
          for file in "${required_files[@]}"; do
            if [[ -f "$file" ]]; then
              echo "✅ $file exists"
            else
              echo "❌ Missing required file: $file"
              exit 1
            fi
          done
          
          required_dirs=("zeros" "data" "logs" "notebooks" "utils" "tests")
          for dir in "${required_dirs[@]}"; do
            if [[ -d "$dir" ]]; then
              echo "✅ $dir/ directory exists"
            else
              echo "❌ Missing required directory: $dir/"
              exit 1
            fi
          done

  prepare-data:
    name: 📊 Prepare Computational Data
    runs-on: ubuntu-latest
    needs: setup-and-validate
    timeout-minutes: 15
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        
      - name: 🐍 Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          
      - name: 💾 Restore dependencies cache
        uses: actions/cache@v4
        with:
          path: ~/.local
          key: ${{ runner.os }}-python-${{ needs.setup-and-validate.outputs.python-version }}-${{ hashFiles('**/requirements.txt') }}
          
      - name: 📊 Fetch and validate zeros data
        run: |
          python utils/fetch_odlyzko.py --precision $PRECISION_LEVEL
          
      - name: 🔐 Validate data integrity
        run: |
          if [[ -f "utils/checksum_zeros.py" ]]; then
            echo "🔍 Running checksum validation..."
            python utils/checksum_zeros.py || echo "⚠️ Checksum validation skipped"
          fi
          
          # Basic validation
          zeros_file="zeros/zeros_${PRECISION_LEVEL}.txt"
          if [[ -f "$zeros_file" ]]; then
            line_count=$(wc -l < "$zeros_file")
            echo "📊 Zeros file contains $line_count lines"
            if (( line_count < 10 )); then
              echo "⚠️ Warning: Very few zeros available ($line_count)"
            else
              echo "✅ Sufficient zeros data available"
            fi
          else
            echo "❌ Zeros file not found: $zeros_file"
            exit 1
          fi
          
      - name: 📤 Upload zeros data as artifact
        uses: actions/upload-artifact@v4
        with:
          name: zeros-data-${{ env.PRECISION_LEVEL }}
          path: zeros/
          retention-days: 7

  run-tests:
    name: 🧪 Run Test Suite
    runs-on: ubuntu-latest
    needs: [setup-and-validate, prepare-data]
    timeout-minutes: 20
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        
      - name: 🐍 Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          
      - name: 💾 Restore dependencies cache
        uses: actions/cache@v4
        with:
          path: ~/.local
          key: ${{ runner.os }}-python-${{ needs.setup-and-validate.outputs.python-version }}-${{ hashFiles('**/requirements.txt') }}
          
      - name: 📥 Download zeros data
        uses: actions/download-artifact@v4
        with:
          name: zeros-data-${{ env.PRECISION_LEVEL }}
          path: zeros/
          
      - name: 🧪 Run pytest with coverage
        run: |
          mkdir -p logs
          pytest tests/ -v --tb=short --cov=. --cov-report=term-missing --cov-report=xml | tee logs/test_results.log
          
      - name: 📊 Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: |
            logs/test_results.log
            coverage.xml
          retention-days: 30

  run-validation:
    name: 🔬 Mathematical Validation
    runs-on: ubuntu-latest
    needs: [setup-and-validate, prepare-data]
    timeout-minutes: 30
    
    strategy:
      matrix:
        validation_type: [standard, weil]
        
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        
      - name: 🐍 Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          
      - name: 💾 Restore dependencies cache
        uses: actions/cache@v4
        with:
          path: ~/.local
          key: ${{ runner.os }}-python-${{ needs.setup-and-validate.outputs.python-version }}-${{ hashFiles('**/requirements.txt') }}
          
      - name: 📥 Download zeros data
        uses: actions/download-artifact@v4
        with:
          name: zeros-data-${{ env.PRECISION_LEVEL }}
          path: zeros/
          
      - name: 🔬 Run validation (${{ matrix.validation_type }})
        run: |
          mkdir -p logs data
          
          if [[ "${{ matrix.validation_type }}" == "weil" ]]; then
            python validate_explicit_formula.py \
              --use_weil_formula \
              --max_primes $PRIME_COUNT \
              --max_zeros $ZERO_COUNT \
              --prime_powers $PRIME_POWERS \
              --integration_t $INTEGRATION_T \
              --precision_dps $PRECISION_DPS \
              2>&1 | tee logs/validation_${{ matrix.validation_type }}.log
          else
            python validate_explicit_formula.py \
              --max_primes $PRIME_COUNT \
              --max_zeros $ZERO_COUNT \
              --prime_powers $PRIME_POWERS \
              --integration_t $INTEGRATION_T \
              --precision_dps $PRECISION_DPS \
              2>&1 | tee logs/validation_${{ matrix.validation_type }}.log
          fi
          
      - name: 📊 Analyze validation results
        run: |
          if [[ -f data/validation_results.csv ]]; then
            echo "📋 Validation Results Summary:"
            cat data/validation_results.csv
            
            # Extract and analyze error metrics
            if grep -q "relative_error" data/validation_results.csv; then
              relative_error=$(grep "relative_error" data/validation_results.csv | cut -d',' -f2)
              echo "📏 Relative error: $relative_error"
              
              # Determine if error is within acceptable bounds (context-dependent)
              if python -c "import sys; sys.exit(0 if float('$relative_error') < 1e-3 else 1)" 2>/dev/null; then
                echo "✅ Error within reasonable bounds for computational validation"
              else
                echo "⚠️ High error detected - this is expected for demonstration purposes"
                echo "🔬 The Riemann Hypothesis requires infinite precision for exact validation"
              fi
            fi
            
            # Copy results with timestamp
            cp data/validation_results.csv data/validation_results_${{ matrix.validation_type }}_$(date +%Y%m%d_%H%M%S).csv
          else
            echo "❌ No validation results found"
            echo "📋 Checking logs for errors..."
            tail -20 logs/validation_${{ matrix.validation_type }}.log
            exit 1
          fi
          
      - name: 📤 Upload validation artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: validation-${{ matrix.validation_type }}-results
          path: |
            logs/validation_${{ matrix.validation_type }}.log
            data/validation_results*.csv
          retention-days: 30

  execute-notebook:
    name: 📒 Execute Jupyter Notebook
    runs-on: ubuntu-latest
    needs: [setup-and-validate, prepare-data]
    timeout-minutes: 45
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        
      - name: 🐍 Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          
      - name: 💾 Restore dependencies cache
        uses: actions/cache@v4
        with:
          path: ~/.local
          key: ${{ runner.os }}-python-${{ needs.setup-and-validate.outputs.python-version }}-${{ hashFiles('**/requirements.txt') }}
          
      - name: 📥 Download zeros data
        uses: actions/download-artifact@v4
        with:
          name: zeros-data-${{ env.PRECISION_LEVEL }}
          path: zeros/
          
      - name: 📒 Execute notebook with timeout
        run: |
          mkdir -p docs logs
          
          echo "🚀 Starting notebook execution with parameters:"
          echo "  PRIME_COUNT=$PRIME_COUNT"
          echo "  ZERO_COUNT=$ZERO_COUNT" 
          echo "  INTEGRATION_T=$INTEGRATION_T"
          echo "  PRECISION_DPS=$PRECISION_DPS"
          
          # Execute notebook with comprehensive error handling
          set +e
          timeout 2400 jupyter nbconvert --to html --execute notebooks/validation.ipynb \
            --output-dir docs/ --output validation_$(date +%Y%m%d_%H%M%S).html \
            --ExecutePreprocessor.timeout=2200 \
            --ExecutePreprocessor.kernel_name=python3 \
            --ExecutePreprocessor.allow_errors=True \
            2>&1 | tee logs/notebook_execution.log
          
          exit_code=$?
          set -e
          
          if [[ $exit_code -eq 0 ]]; then
            echo "✅ Notebook executed successfully"
            ls -la docs/*.html
          elif [[ $exit_code -eq 124 ]]; then
            echo "⏱️ Notebook execution timed out - creating fallback HTML"
            jupyter nbconvert --to html notebooks/validation.ipynb \
              --output-dir docs/ --output validation_static.html
            echo "📋 Static notebook HTML created as fallback"
          else
            echo "⚠️ Notebook execution had issues (exit code: $exit_code)"
            echo "📋 Attempting to create static HTML version..."
            jupyter nbconvert --to html notebooks/validation.ipynb \
              --output-dir docs/ --output validation_static.html || true
          fi
          
      - name: 📊 Extract notebook metrics
        run: |
          echo "📊 Notebook Execution Summary:"
          if [[ -f docs/validation_*.html ]]; then
            html_file=$(ls docs/validation_*.html | head -1)
            file_size=$(ls -lh "$html_file" | awk '{print $5}')
            echo "📄 Generated HTML: $html_file (Size: $file_size)"
            
            # Try to extract timing and error information
            if grep -q "execution_count" "$html_file"; then
              cell_count=$(grep -c "execution_count" "$html_file")
              echo "🧮 Executed cells: $cell_count"
            fi
            
            # Check for any error outputs in HTML
            if grep -qi "error\|exception\|traceback" "$html_file"; then
              echo "⚠️ Some errors detected in notebook execution"
            else
              echo "✅ No obvious errors in notebook output"
            fi
          else
            echo "❌ No HTML output generated"
          fi
          
      - name: 📤 Upload notebook artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: notebook-results
          path: |
            docs/*.html
            logs/notebook_execution.log
          retention-days: 30

  generate-report:
    name: 📋 Generate Summary Report
    runs-on: ubuntu-latest
    needs: [run-tests, run-validation, execute-notebook]
    if: always()
    timeout-minutes: 10
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        
      - name: 📥 Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          
      - name: 📋 Generate comprehensive report
        run: |
          mkdir -p reports
          report_file="reports/ci_summary_$(date +%Y%m%d_%H%M%S).md"
          
          cat > "$report_file" << EOF
          # 🧮 Riemann-Adelic Validation CI Report
          
          **Generated:** $(date)
          **Workflow:** ${{ github.workflow }}
          **Run ID:** ${{ github.run_id }}
          **Commit:** ${{ github.sha }}
          
          ## 📊 Execution Parameters
          - **Precision Level:** $PRECISION_LEVEL
          - **Prime Count:** $PRIME_COUNT
          - **Zero Count:** $ZERO_COUNT
          - **Integration Range:** $INTEGRATION_T
          - **Decimal Precision:** $PRECISION_DPS
          
          ## 🎯 Job Status Summary
          - **Setup & Validation:** ${{ needs.setup-and-validate.result }}
          - **Data Preparation:** ${{ needs.prepare-data.result }}
          - **Test Suite:** ${{ needs.run-tests.result }}
          - **Mathematical Validation:** ${{ needs.run-validation.result }}
          - **Notebook Execution:** ${{ needs.execute-notebook.result }}
          
          ## 📁 Generated Artifacts
          EOF
          
          # List all artifacts
          echo "" >> "$report_file"
          find artifacts/ -type f -name "*.log" -o -name "*.csv" -o -name "*.html" | while read file; do
            size=$(ls -lh "$file" | awk '{print $5}')
            echo "- \`$file\` ($size)" >> "$report_file"
          done
          
          # Add validation results summary if available
          if [[ -f artifacts/validation-*/data/validation_results.csv ]]; then
            echo "" >> "$report_file"
            echo "## 🔬 Latest Validation Results" >> "$report_file"
            echo "\`\`\`csv" >> "$report_file"
            find artifacts/ -name "validation_results.csv" -exec cat {} \; | head -20 >> "$report_file"
            echo "\`\`\`" >> "$report_file"
          fi
          
          echo "📋 Report generated: $report_file"
          cat "$report_file"
          
      - name: 📤 Upload final report
        uses: actions/upload-artifact@v4
        with:
          name: ci-summary-report
          path: reports/
          retention-days: 90